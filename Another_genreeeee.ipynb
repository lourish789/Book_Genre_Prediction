{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Eg0KUimwVI5Gc9C9d1MQHlDPuwopzb-Z",
      "authorship_tag": "ABX9TyN5bzlJNEmJApOcu9UrD801",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lourish789/Book_Genre_Prediction/blob/main/Another_genreeeee.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENRE PREDICTING MODEL"
      ],
      "metadata": {
        "id": "5JedNQRQ_PDv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVy139OJ_IF5",
        "outputId": "5a5e557e-e568-4ca8-fa97-60aa78b594df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.25.1\n"
          ]
        }
      ],
      "source": [
        "pip install PyMuPDF transformers scikit-learn nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "pdf_path = '/content/Literariness.org-Adichie-Chimamanda-Ngozi-Purple-Hibiscus-0-HarperCollins-Publishers.pdf'\n",
        "text = extract_text_from_pdf(pdf_path)\n",
        "#print(text[:500])  # Print the first 500 characters for inspection"
      ],
      "metadata": {
        "id": "TgJrub55_Ocd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text.lower())  # Convert to lower case and tokenize\n",
        "\n",
        "    # Remove stopwords and punctuation\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    punctuation = set(string.punctuation)\n",
        "\n",
        "    tokens = [word for word in tokens if word not in stop_words and word not in punctuation]\n",
        "\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "cleaned_text = preprocess_text(text)\n",
        "#print(cleaned_text[:500])  # Print the cleaned text for inspection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK4UWxuH_XoH",
        "outputId": "1845686e-b65e-4d7d-9fde-cf3810226ba8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the pretrained model for text classification\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# Define possible genres\n",
        "genres = [\n",
        "    \"Romance\", \"Mystery\", \"Thriller\", \"Science Fiction\", \"Fantasy\", \"Horror\",\n",
        "    \"Historical Fiction\", \"Crime\", \"Western\", \"Dystopian\", \"Biography\", \"Autobiography\",\n",
        "    \"Memoir\", \"History\", \"Self-Help\", \"Travel\", \"Essay\", \"Journalism\", \"Sonnet\", \"Haiku\",\n",
        "    \"Free Verse\", \"Narrative Poetry\", \"Lyric Poetry\", \"Tragedy\", \"Comedy\", \"Melodrama\",\n",
        "    \"Farce\", \"Graphic Novel\", \"Epistolary\", \"Magical Realism\", \"Satire\", \"Young Adult Fiction\"\n",
        "]\n",
        "\n",
        "def classify_genre(text):\n",
        "    result = classifier(text, candidate_labels=genres)\n",
        "    return result\n",
        "\n",
        "# Classify the genre of the document\n",
        "result = classify_genre(cleaned_text)\n",
        "#print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8hDILOC_Ya4",
        "outputId": "9b013133-fdb8-40a9-f38b-18e130d22646"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "def rank_genres_by_importance(result):\n",
        "    sorted_genres = sorted(zip(result['labels'], result['scores']), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_genres\n",
        "\n",
        "ranked_genres = rank_genres_by_importance(result)\n",
        "for genre, score in ranked_genres:\n",
        "        hmmm = (f\"Genre: {genre}, Importance: {score*100}\")\n",
        "        print(hmmm)#[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC5rqZX0_Y7I",
        "outputId": "246059c1-86a9-4986-c52c-ccdf407146dd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Genre: Graphic Novel, Importance: 4.24887053668499\n",
            "Genre: Memoir, Importance: 4.0155477821826935\n",
            "Genre: Narrative Poetry, Importance: 3.9616502821445465\n",
            "Genre: Biography, Importance: 3.863532468676567\n",
            "Genre: Satire, Importance: 3.8627225905656815\n",
            "Genre: Autobiography, Importance: 3.7745844572782516\n",
            "Genre: Tragedy, Importance: 3.669922426342964\n",
            "Genre: Essay, Importance: 3.648724779486656\n",
            "Genre: Farce, Importance: 3.589962050318718\n",
            "Genre: Magical Realism, Importance: 3.413081169128418\n",
            "Genre: Sonnet, Importance: 3.3272530883550644\n",
            "Genre: Historical Fiction, Importance: 3.272945061326027\n",
            "Genre: Travel, Importance: 3.215845674276352\n",
            "Genre: Self-Help, Importance: 3.177402541041374\n",
            "Genre: Thriller, Importance: 3.0826371163129807\n",
            "Genre: Haiku, Importance: 3.0488839372992516\n",
            "Genre: Dystopian, Importance: 3.0382173135876656\n",
            "Genre: Melodrama, Importance: 3.0097736045718193\n",
            "Genre: Free Verse, Importance: 3.001697361469269\n",
            "Genre: Epistolary, Importance: 2.8639452531933784\n",
            "Genre: Journalism, Importance: 2.8375908732414246\n",
            "Genre: Horror, Importance: 2.835119515657425\n",
            "Genre: Mystery, Importance: 2.7818771079182625\n",
            "Genre: Crime, Importance: 2.7394620701670647\n",
            "Genre: Romance, Importance: 2.7372095733880997\n",
            "Genre: Lyric Poetry, Importance: 2.6385631412267685\n",
            "Genre: Fantasy, Importance: 2.627292647957802\n",
            "Genre: Comedy, Importance: 2.6243314146995544\n",
            "Genre: Western, Importance: 2.5448868051171303\n",
            "Genre: Young Adult Fiction, Importance: 2.4086501449346542\n",
            "Genre: History, Importance: 2.24520955234766\n",
            "Genre: Science Fiction, Importance: 1.8926093354821205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d1z7z4jY_Z0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mro5uO8y_aNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pose sequence as a NLI premise and label as a hypothesis\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
        "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
        "\n",
        "premise = sequence\n",
        "hypothesis = f'This example is {label}.'\n",
        "\n",
        "# run through model pre-trained on MNLI\n",
        "x = tokenizer.encode(premise, hypothesis, return_tensors='pt',\n",
        "                     truncation_strategy='only_first')\n",
        "logits = nli_model(x.to(device))[0]\n",
        "\n",
        "# we throw away \"neutral\" (dim 1) and take the probability of\n",
        "# \"entailment\" (2) as the probability of the label being true\n",
        "entail_contradiction_logits = logits[:,[0,2]]\n",
        "probs = entail_contradiction_logits.softmax(dim=1)\n",
        "prob_label_is_true = probs[:,1]"
      ],
      "metadata": {
        "id": "7zKxpVtexRfi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "000be474-7de9-416a-eebd-6cf0541b7808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sequence' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-792abb4e2cc4>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'facebook/bart-large-mnli'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpremise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'This example is {label}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sequence' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./genre_model\")\n",
        "tokenizer.save_pretrained(\"./genre_model\")"
      ],
      "metadata": {
        "id": "3E5BA-Hz_ZZQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}